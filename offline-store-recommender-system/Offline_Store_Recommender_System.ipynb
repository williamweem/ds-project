{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "oldHeight": 529.444222,
      "position": {
        "height": "40px",
        "left": "775.319px",
        "right": "20px",
        "top": "165px",
        "width": "800px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "varInspector_section_display": "none",
      "window_display": false
    },
    "colab": {
      "name": "Offline Store Recommender System.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williamweem/one-notebook-ds-project/blob/master/offline-store-recommender-system/Offline_Store_Recommender_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UhnnSpmBk_d",
        "colab_type": "text"
      },
      "source": [
        "## Import Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBG0P9u0FMqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "51c988d5-ef38-4259-97e2-64e3ccd29761"
      },
      "source": [
        "! pip install surprise"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting surprise\n",
            "  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/da/b5700d96495fb4f092be497f02492768a3d96a3f4fa2ae7dea46d4081cfa/scikit-surprise-1.1.0.tar.gz (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.18.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.12.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.0-cp36-cp36m-linux_x86_64.whl size=1675403 sha256=56f43c9169c4237bcd7b235dfe9dc70ce5e272929cb2dc540016b5ab276ecd48\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/fa/8c/16c93fccce688ae1bde7d979ff102f7bee980d9cfeb8641bcf\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.0 surprise-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3HogXIoBk_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import SVD\n",
        "from surprise import NMF\n",
        "\n",
        "pd.options.display.float_format = \"{:.2f}\".format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5_LNTdIDTwb",
        "colab_type": "text"
      },
      "source": [
        "## Data Upload and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJtV-1KUBk_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"data untuk olah.csv\")\n",
        "\n",
        "df = df[df[\"Kategori Pelanggan\"]!=\"UMUM\"].copy()\n",
        "df = df[df[\"Kode Pelanggan\"]!=\"GRO\"].copy()\n",
        "df = df[df[\"Kode Pelanggan\"]!=\"HTRSTO\"].copy()\n",
        "df = df[df[\"DPP+Pajak\"]>2].copy()\n",
        "df = df[~df[\"Nama Produk\"].str.contains(\"MEMBER CARD\")].copy()\n",
        "\n",
        "le = LabelEncoder()\n",
        "#\n",
        "le.fit(df['Kode Pelanggan'])\n",
        "kode_pelanggan_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
        "df['Kode Pelanggan'] = le.transform(df['Kode Pelanggan']).astype(\"str\")\n",
        "#\n",
        "le.fit(df['Kode Produk'])\n",
        "kode_produk_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
        "df['Kode Produk'] = le.transform(df['Kode Produk']).astype(\"str\")\n",
        "#\n",
        "le.fit(df['Kategori Produk'])\n",
        "kode_kategori_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
        "df['Kategori Produk'] = le.transform(df['Kategori Produk']).astype(\"str\")\n",
        "#\n",
        "df[\"Tanggal\"] = pd.to_datetime(df[\"Tanggal\"])\n",
        "#\n",
        "df = df.drop(\"Nama Produk\", axis=1)\n",
        "#\n",
        "# df_bukti = df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu0adrK1Bk_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "a696b0ee-fc94-48ac-f93e-b460678a7546"
      },
      "source": [
        "for i in range(15):\n",
        "    if i+9>12:\n",
        "        tahun = \"2019\"\n",
        "        if i-3>9:\n",
        "            bulan = str(i-3)\n",
        "        else:\n",
        "            bulan = \"0\"+str(i-3)\n",
        "        print(\"{} {}: {}\".format(tahun, bulan, df[df[\"Tanggal\"] < pd.Timestamp(tahun+bulan+\"01\")][\"Kode Pelanggan\"].nunique()))\n",
        "    else:\n",
        "        tahun = \"2018\"\n",
        "        if i+9>9:\n",
        "            bulan = str(i+9)\n",
        "        else:\n",
        "            bulan = \"0\"+str(i+9)\n",
        "        print(\"{} {}: {}\".format(tahun, bulan, df[df[\"Tanggal\"] < pd.Timestamp(tahun+bulan+\"01\")][\"Kode Pelanggan\"].nunique()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018 09: 0\n",
            "2018 10: 2494\n",
            "2018 11: 4062\n",
            "2018 12: 5407\n",
            "2019 01: 6962\n",
            "2019 02: 8071\n",
            "2019 03: 8913\n",
            "2019 04: 9865\n",
            "2019 05: 10879\n",
            "2019 06: 12052\n",
            "2019 07: 12954\n",
            "2019 08: 13843\n",
            "2019 09: 14515\n",
            "2019 10: 15491\n",
            "2019 11: 15521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tsHnBEMTBlAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d66db0f8-4ed2-42d9-bdaf-96a5e5bedba2"
      },
      "source": [
        "ts = time.time()\n",
        "\n",
        "set1 = df[df[\"Tanggal\"] <= pd.Timestamp('20181231')].copy()\n",
        "set2 = df[(df[\"Tanggal\"] >= pd.Timestamp('20190101')) & (df[\"Tanggal\"] <= pd.Timestamp('20190129'))].copy()\n",
        "set3 = df[(df[\"Tanggal\"] >= pd.Timestamp('20190130')) & (df[\"Tanggal\"] <= pd.Timestamp('20190226'))].copy()\n",
        "set4 = df[(df[\"Tanggal\"] >= pd.Timestamp('20190227')) & (df[\"Tanggal\"] <= pd.Timestamp('20190326'))].copy()\n",
        "set5 = df[(df[\"Tanggal\"] >= pd.Timestamp('20190327')) & (df[\"Tanggal\"] <= pd.Timestamp('20190423'))].copy()\n",
        "set6 = df[(df[\"Tanggal\"] >= pd.Timestamp('20190424')) & (df[\"Tanggal\"] <= pd.Timestamp('20190521'))].copy()\n",
        "set7 = df[(df[\"Tanggal\"] >= pd.Timestamp('20190522')) & (df[\"Tanggal\"] <= pd.Timestamp('20190618'))].copy()\n",
        "set8 = df[(df[\"Tanggal\"] >= pd.Timestamp('20190619')) & (df[\"Tanggal\"] <= pd.Timestamp('20190716'))].copy()\n",
        "set9 = df[(df[\"Tanggal\"] >= pd.Timestamp('20190717')) & (df[\"Tanggal\"] <= pd.Timestamp('20190813'))].copy()\n",
        "set10 = df[(df[\"Tanggal\"] >= pd.Timestamp('20190814')) & (df[\"Tanggal\"] <= pd.Timestamp('20190910'))].copy()\n",
        "set11 = df[(df[\"Tanggal\"] >= pd.Timestamp('20190911')) & (df[\"Tanggal\"] <= pd.Timestamp('20190915'))].copy()\n",
        "\n",
        "train2 = set1.append(set2, ignore_index=True)\n",
        "train3 = train2.append(set3, ignore_index=True)\n",
        "train4 = train3.append(set4, ignore_index=True)\n",
        "train5 = train3.append(set5, ignore_index=True)\n",
        "train6 = train3.append(set6, ignore_index=True)\n",
        "train7 = train3.append(set7, ignore_index=True)\n",
        "train8 = train3.append(set8, ignore_index=True)\n",
        "train9 = train3.append(set9, ignore_index=True)\n",
        "train10 = train3.append(set10, ignore_index=True)\n",
        "\n",
        "time.time()-ts"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34326982498168945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20WEoO9sBlAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_tabular(df):\n",
        "    df = df.groupby([\"Kode Pelanggan\",\"Kategori Produk\"])[[\"Kategori Produk\"]].count()\n",
        "    df = df.rename(columns={\"Kategori Produk\":\"Jumlah Pembelian\"}).reset_index()\n",
        "    df['Kode Pelanggan'] = df['Kode Pelanggan'].astype(np.int64)\n",
        "    df['Kategori Produk'] = df['Kategori Produk'].astype(np.int64)\n",
        "    df = df.sort_values(by=[\"Kode Pelanggan\",\"Kategori Produk\"]).reset_index(drop=True)\n",
        "    # Klo mau versi dummy\n",
        "    df['Dummy'] = 1\n",
        "    # Klo mau versi normalized\n",
        "    df[\"Max Pembelian\"] = df.groupby(\"Kategori Produk\")[[\"Jumlah Pembelian\"]].transform(\"max\")\n",
        "    df[\"Jumlah Norm\"] = df[\"Jumlah Pembelian\"] / df[\"Max Pembelian\"]\n",
        "    df = df.drop([\"Max Pembelian\"], axis=1)\n",
        "    return df\n",
        "\n",
        "def to_pm(df):\n",
        "    # Pilih values = \"Jumlah Pembelian\", \"Dummy\", \"Jumlah Norm\"\n",
        "    df = df.pivot(index=\"Kode Pelanggan\", columns=\"Kategori Produk\", values=\"Dummy\").fillna(0).reset_index()\n",
        "    df.columns.name = None\n",
        "    df.drop(\"Kode Pelanggan\", axis=1, inplace=True)\n",
        "    df = df.transpose()\n",
        "    df = df.reindex(range(0,175), fill_value=0)\n",
        "    return df\n",
        "\n",
        "def to_ss(df):\n",
        "    # Pilih values dan value_name = \"Jumlah Pembelian\", \"Dummy\", \"Jumlah Norm\"\n",
        "    df = df.pivot(index=\"Kode Pelanggan\", columns=\"Kategori Produk\", values=\"Dummy\").fillna(0).reset_index()\n",
        "    df.columns.name = None\n",
        "    df = df.melt(id_vars=\"Kode Pelanggan\", var_name=\"Kategori Produk\", value_name=\"Dummy\")\n",
        "    return df\n",
        "\n",
        "def persiapan_test_ss(df, train):\n",
        "    df = to_ss(to_tabular(df))\n",
        "    df = df[df[\"Kode Pelanggan\"].isin(df[\"Kode Pelanggan\"].unique()\n",
        "                                            [np.isin(df[\"Kode Pelanggan\"].unique(), \n",
        "                                            train[\"Kode Pelanggan\"].unique())])].copy()\n",
        "    return df\n",
        "\n",
        "def ss_result(fit, test, N=5, set=1):\n",
        "    pred = fit.test(test)\n",
        "    result = pd.DataFrame(pred, columns=['Kode Pelanggan', 'Kategori Produk', 'Realita', 'Prediksi', 'details'])\n",
        "    result.drop(columns = {'details'}, inplace = True)\n",
        "    result = result.sort_values(['Kode Pelanggan','Prediksi'], ascending=False).groupby('Kode Pelanggan').head(N)\n",
        "    result[\"Set\"]=set\n",
        "    return result\n",
        "\n",
        "def pred_summary(df, test_all):\n",
        "    df = df.groupby([\"Kode Pelanggan\", \"Set\"], as_index=False)[\"Realita\"].sum()\n",
        "    df.rename(columns={\"Realita\":\"Jumlah Prediksi Benar\"}, inplace=True)\n",
        "    # Satuin semua test data disini\n",
        "    df = df.merge(test_all, on=[\"Kode Pelanggan\",\"Set\"])\n",
        "    df.rename(columns={\"Dummy\":\"Jumlah Jenis Barang\"}, inplace=True)\n",
        "    df[\"Precision\"] = df[\"Jumlah Prediksi Benar\"]/5\n",
        "    df[\"Recall\"] = df[\"Jumlah Prediksi Benar\"]/df[\"Jumlah Jenis Barang\"]\n",
        "    df[\"F1 Score\"] = (2*df[\"Precision\"]*df[\"Recall\"])/(df[\"Recall\"]+df[\"Precision\"])\n",
        "    df[\"F1 Score\"] = df[\"F1 Score\"].fillna(0)\n",
        "    return df\n",
        "\n",
        "def cosine_rec(cs_mat, test):\n",
        "    result_np_1_cs = np.empty(shape=[0, 3])\n",
        "    for j in test:\n",
        "        temp = np.vstack((np.repeat(j, 10) , cs_mat[j].argsort()[-11:-1][::-1] , np.sort(cs_mat[j])[-11:-1][::-1])).T\n",
        "        result_np_1_cs = np.append(result_np_1_cs, temp, axis=0)\n",
        "        \n",
        "    result_1_cs = pd.DataFrame(result_np_1_cs, columns=[\"Origin\", \"Kategori Produk\", \"Prediksi\"])\n",
        "    result_1_cs = result_1_cs.drop_duplicates('Kategori Produk').nlargest(5, 'Prediksi')\n",
        "    # Kalau kodenya udah mateng, 2 hashtag dibawah bisa dibuka (ngeberatin soalnya)\n",
        "    # result_1_cs[\"Origin Item Name\"] = result_1_cs[\"Origin Item\"].apply(lambda x: kode_kategori_mapping[x])\n",
        "    # result_1_cs[\"Recommended Item Name\"] = result_1_cs[\"Recommended Item\"].apply(lambda x: kode_kategori_mapping[x])\n",
        "    return result_1_cs\n",
        "\n",
        "def persiapan_test_cs(df, train_tab):\n",
        "    # Pilih yang di drop = \"Jumlah Pembelian\", \"Dummy\", \"Jumlah Norm\"\n",
        "    df = to_tabular(df).drop([\"Jumlah Pembelian\",\"Jumlah Norm\"], axis=1)\n",
        "    df = df[df[\"Kode Pelanggan\"].isin(df[\"Kode Pelanggan\"].unique()\n",
        "                                     [np.isin(df[\"Kode Pelanggan\"].unique(), \n",
        "                                     train_tab[\"Kode Pelanggan\"].unique())])].copy()\n",
        "    return df\n",
        "\n",
        "def testing_cs(fit, train_tab, test, set=1):\n",
        "    result = pd.DataFrame()\n",
        "    for i in test[\"Kode Pelanggan\"].unique():\n",
        "        temp = train_tab[train_tab[\"Kode Pelanggan\"]==i][\"Kategori Produk\"].unique()\n",
        "        result_cs = cosine_rec(fit, temp)\n",
        "        result_cs[\"Realita\"] = 1 * result_cs[\"Kategori Produk\"].isin(test[test[\"Kode Pelanggan\"]==i][\"Kategori Produk\"].unique())\n",
        "        result_cs[\"Kode Pelanggan\"] = i\n",
        "        result = pd.concat([result,result_cs], ignore_index=True)\n",
        "        print(i)\n",
        "    result[\"Set\"] = set\n",
        "    print(\"Next one\")    \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h5k3z5lBlAR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "324d945a-d2c8-4312-afef-b401ad0e6713"
      },
      "source": [
        "ts = time.time()\n",
        "\n",
        "train1_ss = to_ss(to_tabular(set1))\n",
        "train2_ss = to_ss(to_tabular(train2))\n",
        "train3_ss = to_ss(to_tabular(train3))\n",
        "train4_ss = to_ss(to_tabular(train4))\n",
        "train5_ss = to_ss(to_tabular(train5))\n",
        "train6_ss = to_ss(to_tabular(train6))\n",
        "train7_ss = to_ss(to_tabular(train7))\n",
        "train8_ss = to_ss(to_tabular(train8))\n",
        "train9_ss = to_ss(to_tabular(train9))\n",
        "train10_ss = to_ss(to_tabular(train10))\n",
        "\n",
        "test1_ss = persiapan_test_ss(set2, train=train1_ss)\n",
        "test2_ss = persiapan_test_ss(set3, train=train2_ss)\n",
        "test3_ss = persiapan_test_ss(set4, train=train3_ss)\n",
        "test4_ss = persiapan_test_ss(set5, train=train4_ss)\n",
        "test5_ss = persiapan_test_ss(set6, train=train5_ss)\n",
        "test6_ss = persiapan_test_ss(set7, train=train6_ss)\n",
        "test7_ss = persiapan_test_ss(set8, train=train7_ss)\n",
        "test8_ss = persiapan_test_ss(set9, train=train8_ss)\n",
        "test9_ss = persiapan_test_ss(set10, train=train9_ss)\n",
        "test10_ss = persiapan_test_ss(set11, train=train10_ss)\n",
        "\n",
        "# Disesuaikan apabila \"Dummy\" atau \"Jumlah Norm\"\n",
        "test_ss_all = pd.concat([test1_ss.assign(Set = lambda x:1).groupby([\"Kode Pelanggan\",\"Set\"], as_index=False)[[\"Dummy\"]].sum(),\n",
        "                            test2_ss.assign(Set = lambda x:2).groupby([\"Kode Pelanggan\",\"Set\"], as_index=False)[[\"Dummy\"]].sum(),\n",
        "                            test3_ss.assign(Set = lambda x:3).groupby([\"Kode Pelanggan\",\"Set\"], as_index=False)[[\"Dummy\"]].sum(),\n",
        "                            test4_ss.assign(Set = lambda x:4).groupby([\"Kode Pelanggan\",\"Set\"], as_index=False)[[\"Dummy\"]].sum(),\n",
        "                            test5_ss.assign(Set = lambda x:5).groupby([\"Kode Pelanggan\",\"Set\"], as_index=False)[[\"Dummy\"]].sum(),\n",
        "                            test6_ss.assign(Set = lambda x:6).groupby([\"Kode Pelanggan\",\"Set\"], as_index=False)[[\"Dummy\"]].sum(),\n",
        "                            test7_ss.assign(Set = lambda x:7).groupby([\"Kode Pelanggan\",\"Set\"], as_index=False)[[\"Dummy\"]].sum(),\n",
        "                            test8_ss.assign(Set = lambda x:8).groupby([\"Kode Pelanggan\",\"Set\"], as_index=False)[[\"Dummy\"]].sum(),\n",
        "                            test9_ss.assign(Set = lambda x:9).groupby([\"Kode Pelanggan\",\"Set\"], as_index=False)[[\"Dummy\"]].sum(),\n",
        "                            test10_ss.assign(Set = lambda x:10).groupby([\"Kode Pelanggan\",\"Set\"], as_index=False)[[\"Dummy\"]].sum()],\n",
        "                            ignore_index=True)\n",
        "\n",
        "time.time()-ts"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.950901508331299"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNNwzHIgDewI",
        "colab_type": "text"
      },
      "source": [
        "## Recommender System using Funk's SVD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXW0l1z1PSXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "747f47a3-ceac-43aa-ec1a-970a074bbee9"
      },
      "source": [
        "ts = time.time()\n",
        "\n",
        "svd = SVD(n_factors=100,n_epochs=100,lr_all=0.005,reg_all=0.02)\n",
        "# Klo mau pake \"Jumlah Pembelian\", rating_scalenya mesti disesuaikan\n",
        "reader = Reader(rating_scale=(0, 1))\n",
        "\n",
        "train1_svd = Dataset.load_from_df(train1_ss, reader).build_full_trainset()\n",
        "train2_svd = Dataset.load_from_df(train2_ss, reader).build_full_trainset()\n",
        "train3_svd = Dataset.load_from_df(train3_ss, reader).build_full_trainset()\n",
        "train4_svd = Dataset.load_from_df(train4_ss, reader).build_full_trainset()\n",
        "train5_svd = Dataset.load_from_df(train5_ss, reader).build_full_trainset()\n",
        "train6_svd = Dataset.load_from_df(train6_ss, reader).build_full_trainset()\n",
        "train7_svd = Dataset.load_from_df(train7_ss, reader).build_full_trainset()\n",
        "train8_svd = Dataset.load_from_df(train8_ss, reader).build_full_trainset()\n",
        "train9_svd = Dataset.load_from_df(train9_ss, reader).build_full_trainset()\n",
        "train10_svd = Dataset.load_from_df(train10_ss, reader).build_full_trainset()\n",
        "\n",
        "test1_svd = Dataset.load_from_df(test1_ss, reader).build_full_trainset().build_testset()\n",
        "test2_svd = Dataset.load_from_df(test2_ss, reader).build_full_trainset().build_testset()\n",
        "test3_svd = Dataset.load_from_df(test3_ss, reader).build_full_trainset().build_testset()\n",
        "test4_svd = Dataset.load_from_df(test4_ss, reader).build_full_trainset().build_testset()\n",
        "test5_svd = Dataset.load_from_df(test5_ss, reader).build_full_trainset().build_testset()\n",
        "test6_svd = Dataset.load_from_df(test6_ss, reader).build_full_trainset().build_testset()\n",
        "test7_svd = Dataset.load_from_df(test7_ss, reader).build_full_trainset().build_testset()\n",
        "test8_svd = Dataset.load_from_df(test8_ss, reader).build_full_trainset().build_testset()\n",
        "test9_svd = Dataset.load_from_df(test9_ss, reader).build_full_trainset().build_testset()\n",
        "test10_svd = Dataset.load_from_df(test10_ss, reader).build_full_trainset().build_testset()\n",
        "\n",
        "print(\"Fit 1 Dimulai\")\n",
        "svd1_fit = svd.fit(train1_svd)\n",
        "print(\"Fit 2 Dimulai\")\n",
        "svd2_fit = svd.fit(train2_svd)\n",
        "print(\"Fit 3 Dimulai\")\n",
        "svd3_fit = svd.fit(train3_svd)\n",
        "print(\"Fit 4 Dimulai\")\n",
        "svd4_fit = svd.fit(train4_svd)\n",
        "print(\"Fit 5 Dimulai\")\n",
        "svd5_fit = svd.fit(train5_svd)\n",
        "print(\"Fit 6 Dimulai\")\n",
        "svd6_fit = svd.fit(train6_svd)\n",
        "print(\"Fit 7 Dimulai\")\n",
        "svd7_fit = svd.fit(train7_svd)\n",
        "print(\"Fit 8 Dimulai\")\n",
        "svd8_fit = svd.fit(train8_svd)\n",
        "print(\"Fit 9 Dimulai\")\n",
        "svd9_fit = svd.fit(train9_svd)\n",
        "print(\"Fit 10 Dimulai\")\n",
        "svd10_fit = svd.fit(train10_svd)\n",
        "\n",
        "print(\"Tes Dimulai\")\n",
        "pred1_svd = ss_result(svd1_fit,test1_svd, set=1)\n",
        "print(\"Tahap 1 Selesai\")\n",
        "pred2_svd = ss_result(svd2_fit,test2_svd, set=2)\n",
        "print(\"Tahap 2 Selesai\")\n",
        "pred3_svd = ss_result(svd3_fit,test3_svd, set=3)\n",
        "print(\"Tahap 3 Selesai\")\n",
        "pred4_svd = ss_result(svd4_fit,test4_svd, set=4)\n",
        "print(\"Tahap 4 Selesai\")\n",
        "pred5_svd = ss_result(svd5_fit,test5_svd, set=5)\n",
        "print(\"Tahap 5 Selesai\")\n",
        "pred6_svd = ss_result(svd6_fit,test6_svd, set=6)\n",
        "print(\"Tahap 6 Selesai\")\n",
        "pred7_svd = ss_result(svd7_fit,test7_svd, set=7)\n",
        "print(\"Tahap 7 Selesai\")\n",
        "pred8_svd = ss_result(svd8_fit,test8_svd, set=8)\n",
        "print(\"Tahap 8 Selesai\")\n",
        "pred9_svd = ss_result(svd9_fit,test9_svd, set=9)\n",
        "print(\"Tahap 9 Selesai\")\n",
        "pred10_svd = ss_result(svd10_fit,test10_svd, set=10)\n",
        "print(\"Tahap 10 Selesai\")\n",
        "\n",
        "pred_svd = pd.concat([pred1_svd, pred2_svd, pred3_svd, pred4_svd, pred5_svd, pred6_svd, pred7_svd, pred8_svd, pred9_svd, pred10_svd], ignore_index=True)\n",
        "pred_svd_summary = pred_summary(pred_svd, test_all=test_ss_all)\n",
        "\n",
        "print(\"Precision value = {}\".format(pred_svd_summary[\"Precision\"].mean()))\n",
        "print(\"Recall value = {}\".format(pred_svd_summary[\"Recall\"].mean()))\n",
        "print(\"F1 Score value = {}\".format(pred_svd_summary[\"F1 Score\"].mean()))\n",
        "\n",
        "print(\"Time Elapsed: {}\".format(time.time()-ts))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fit 1 Dimulai\n",
            "Fit 2 Dimulai\n",
            "Fit 3 Dimulai\n",
            "Fit 4 Dimulai\n",
            "Fit 5 Dimulai\n",
            "Fit 6 Dimulai\n",
            "Fit 7 Dimulai\n",
            "Fit 8 Dimulai\n",
            "Fit 9 Dimulai\n",
            "Fit 10 Dimulai\n",
            "Tes Dimulai\n",
            "Tahap 1 Selesai\n",
            "Tahap 2 Selesai\n",
            "Tahap 3 Selesai\n",
            "Tahap 4 Selesai\n",
            "Tahap 5 Selesai\n",
            "Tahap 6 Selesai\n",
            "Tahap 7 Selesai\n",
            "Tahap 8 Selesai\n",
            "Tahap 9 Selesai\n",
            "Tahap 10 Selesai\n",
            "Precision value = 0.2283593002981077\n",
            "Recall value = 0.18718915601567285\n",
            "F1 Score value = 0.17050707428476736\n",
            "Time Elapsed: 4713.6064121723175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoiFS1mwDo-W",
        "colab_type": "text"
      },
      "source": [
        "## Recommender System using Non-Negative Matrix Factorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JHhzfVd4BlAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "f4536561-bb3a-4630-c763-ec568110ff28"
      },
      "source": [
        "ts = time.time()\n",
        "\n",
        "nmf = NMF()\n",
        "# Klo mau pake \"Jumlah Pembelian\", rating_scalenya mesti disesuaikan\n",
        "reader = Reader(rating_scale=(0, 1))\n",
        "\n",
        "train1_nmf = Dataset.load_from_df(train1_ss, reader).build_full_trainset()\n",
        "train2_nmf = Dataset.load_from_df(train2_ss, reader).build_full_trainset()\n",
        "train3_nmf = Dataset.load_from_df(train3_ss, reader).build_full_trainset()\n",
        "train4_nmf = Dataset.load_from_df(train4_ss, reader).build_full_trainset()\n",
        "train5_nmf = Dataset.load_from_df(train5_ss, reader).build_full_trainset()\n",
        "train6_nmf = Dataset.load_from_df(train6_ss, reader).build_full_trainset()\n",
        "train7_nmf = Dataset.load_from_df(train7_ss, reader).build_full_trainset()\n",
        "train8_nmf = Dataset.load_from_df(train8_ss, reader).build_full_trainset()\n",
        "train9_nmf = Dataset.load_from_df(train9_ss, reader).build_full_trainset()\n",
        "train10_nmf = Dataset.load_from_df(train10_ss, reader).build_full_trainset()\n",
        "\n",
        "test1_nmf = Dataset.load_from_df(test1_ss, reader).build_full_trainset().build_testset()\n",
        "test2_nmf = Dataset.load_from_df(test2_ss, reader).build_full_trainset().build_testset()\n",
        "test3_nmf = Dataset.load_from_df(test3_ss, reader).build_full_trainset().build_testset()\n",
        "test4_nmf = Dataset.load_from_df(test4_ss, reader).build_full_trainset().build_testset()\n",
        "test5_nmf = Dataset.load_from_df(test5_ss, reader).build_full_trainset().build_testset()\n",
        "test6_nmf = Dataset.load_from_df(test6_ss, reader).build_full_trainset().build_testset()\n",
        "test7_nmf = Dataset.load_from_df(test7_ss, reader).build_full_trainset().build_testset()\n",
        "test8_nmf = Dataset.load_from_df(test8_ss, reader).build_full_trainset().build_testset()\n",
        "test9_nmf = Dataset.load_from_df(test9_ss, reader).build_full_trainset().build_testset()\n",
        "test10_nmf = Dataset.load_from_df(test10_ss, reader).build_full_trainset().build_testset()\n",
        "\n",
        "print(\"Fit 1 Dimulai\")\n",
        "nmf1_fit = nmf.fit(train1_nmf)\n",
        "print(\"Fit 2 Dimulai\")\n",
        "nmf2_fit = nmf.fit(train2_nmf)\n",
        "print(\"Fit 3 Dimulai\")\n",
        "nmf3_fit = nmf.fit(train3_nmf)\n",
        "print(\"Fit 4 Dimulai\")\n",
        "nmf4_fit = nmf.fit(train4_nmf)\n",
        "print(\"Fit 5 Dimulai\")\n",
        "nmf5_fit = nmf.fit(train5_nmf)\n",
        "print(\"Fit 6 Dimulai\")\n",
        "nmf6_fit = nmf.fit(train6_nmf)\n",
        "print(\"Fit 7 Dimulai\")\n",
        "nmf7_fit = nmf.fit(train7_nmf)\n",
        "print(\"Fit 8 Dimulai\")\n",
        "nmf8_fit = nmf.fit(train8_nmf)\n",
        "print(\"Fit 9 Dimulai\")\n",
        "nmf9_fit = nmf.fit(train9_nmf)\n",
        "print(\"Fit 10 Dimulai\")\n",
        "nmf10_fit = nmf.fit(train10_nmf)\n",
        "\n",
        "print(\"Tes Dimulai\")\n",
        "pred1_nmf = ss_result(nmf1_fit,test1_nmf, set=1)\n",
        "print(\"Tahap 1 Selesai\")\n",
        "pred2_nmf = ss_result(nmf2_fit,test2_nmf, set=2)\n",
        "print(\"Tahap 2 Selesai\")\n",
        "pred3_nmf = ss_result(nmf3_fit,test3_nmf, set=3)\n",
        "print(\"Tahap 3 Selesai\")\n",
        "pred4_nmf = ss_result(nmf4_fit,test4_nmf, set=4)\n",
        "print(\"Tahap 4 Selesai\")\n",
        "pred5_nmf = ss_result(nmf5_fit,test5_nmf, set=5)\n",
        "print(\"Tahap 5 Selesai\")\n",
        "pred6_nmf = ss_result(nmf6_fit,test6_nmf, set=6)\n",
        "print(\"Tahap 6 Selesai\")\n",
        "pred7_nmf = ss_result(nmf7_fit,test7_nmf, set=7)\n",
        "print(\"Tahap 7 Selesai\")\n",
        "pred8_nmf = ss_result(nmf8_fit,test8_nmf, set=8)\n",
        "print(\"Tahap 8 Selesai\")\n",
        "pred9_nmf = ss_result(nmf9_fit,test9_nmf, set=9)\n",
        "print(\"Tahap 9 Selesai\")\n",
        "pred10_nmf = ss_result(nmf10_fit,test10_nmf, set=10)\n",
        "print(\"Tahap 10 Selesai\")\n",
        "\n",
        "pred_nmf = pd.concat([pred1_nmf, pred2_nmf, pred3_nmf, pred4_nmf, pred5_nmf, pred6_nmf, pred7_nmf, pred8_nmf, pred9_nmf, pred10_nmf], ignore_index=True)\n",
        "pred_nmf_summary = pred_summary(pred_nmf, test_all=test_ss_all)\n",
        "\n",
        "print(\"Precision value = {}\".format(pred_nmf_summary[\"Precision\"].mean()))\n",
        "print(\"Recall value = {}\".format(pred_nmf_summary[\"Recall\"].mean()))\n",
        "print(\"F1 Score value = {}\".format(pred_nmf_summary[\"F1 Score\"].mean()))\n",
        "\n",
        "print(\"Time Elapsed: {}\".format(time.time()-ts))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fit 1 Dimulai\n",
            "Fit 2 Dimulai\n",
            "Fit 3 Dimulai\n",
            "Fit 4 Dimulai\n",
            "Fit 5 Dimulai\n",
            "Fit 6 Dimulai\n",
            "Fit 7 Dimulai\n",
            "Fit 8 Dimulai\n",
            "Fit 9 Dimulai\n",
            "Fit 10 Dimulai\n",
            "Tes Dimulai\n",
            "Tahap 1 Selesai\n",
            "Tahap 2 Selesai\n",
            "Tahap 3 Selesai\n",
            "Tahap 4 Selesai\n",
            "Tahap 5 Selesai\n",
            "Tahap 6 Selesai\n",
            "Tahap 7 Selesai\n",
            "Tahap 8 Selesai\n",
            "Tahap 9 Selesai\n",
            "Tahap 10 Selesai\n",
            "Precision value = 0.1950953371955694\n",
            "Recall value = 0.1531902026794957\n",
            "F1 Score value = 0.141507123988583\n",
            "Time Elapsed: 1062.348631620407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mob01shOpv1",
        "colab_type": "text"
      },
      "source": [
        "## Example of Recommendation Given to User (Funk's SVD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQVjD9VtOuRU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "ead0c95d-e803-42a5-a69e-ddf264882a6b"
      },
      "source": [
        "pd.set_option('max_rows', 1000)\n",
        "pred_svd"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kode Pelanggan</th>\n",
              "      <th>Kategori Produk</th>\n",
              "      <th>Realita</th>\n",
              "      <th>Prediksi</th>\n",
              "      <th>Set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15518</td>\n",
              "      <td>122</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.97</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15518</td>\n",
              "      <td>83</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.95</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15518</td>\n",
              "      <td>41</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15518</td>\n",
              "      <td>171</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15518</td>\n",
              "      <td>172</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.85</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88890</th>\n",
              "      <td>125</td>\n",
              "      <td>122</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88891</th>\n",
              "      <td>125</td>\n",
              "      <td>70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.19</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88892</th>\n",
              "      <td>125</td>\n",
              "      <td>172</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.17</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88893</th>\n",
              "      <td>125</td>\n",
              "      <td>33</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.16</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88894</th>\n",
              "      <td>125</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.16</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88895 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Kode Pelanggan  Kategori Produk  Realita  Prediksi  Set\n",
              "0               15518              122     1.00      0.97    1\n",
              "1               15518               83     1.00      0.95    1\n",
              "2               15518               41     0.00      0.92    1\n",
              "3               15518              171     0.00      0.92    1\n",
              "4               15518              172     0.00      0.85    1\n",
              "...               ...              ...      ...       ...  ...\n",
              "88890             125              122     0.00      0.20   10\n",
              "88891             125               70     0.00      0.19   10\n",
              "88892             125              172     1.00      0.17   10\n",
              "88893             125               33     1.00      0.16   10\n",
              "88894             125                0     0.00      0.16   10\n",
              "\n",
              "[88895 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}